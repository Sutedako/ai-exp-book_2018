%!TEX root = ../main.tex



\section{CNN応用分野}
これより先はCNNの応用分野であり，必須課題ではない．
画像分類以外にどのような方法でCNNが利用されているかをいくつか述べるものである．

\subsection{深層特徴}
第二章では最終層にsoftmax関数をかけてクラスの確率分布を出力していた．
CNN は最終層以外の中間層の出力も有用である．
例えば以下のVGGと呼ばれるCNNではFC6層，FC7層の値を利用することが頻繁にある．

CNNは特徴抽出と分類/回帰を同時に行うモデルである．分類/回帰の結果は最終層に現れるが，特徴表現は隠れ層に出てくるとされている．
何らかの課題を学習したCNNは，データのより良い表現(特徴)の表現を隠れ層で学習している．そのため，データの良い特徴を得るという目的で「学習済みのCNN」にデータを通しその際の隠れ層の出力を取得する，ということがよく行われる．


\begin{itembox}[l]{CNNの特徴抽出}
より正確には，CNNは最終的なタスク(分類/回帰)を行なうのに有用な特徴表現を学習する．
例えばある画像を入力に「人物が写っているか/写っていないか」の2値分類をCNNで解く場合，
恐らくCNNはそこに鳥がいるか空が写っているかなどの情報は無視して，人間の存在を分けるような特徴の表現を学習するだろう．
\end{itembox}


\subsubsection{深層特徴の利用方法}
単純に分類問題や回帰問題を解く場合は，end-to-endなネットワークを構築して学習した方が精度が高い．
しかし，ネットワーク上に問題を落とし込めない時，深層特徴だけを利用するケースがある．
例えば，画像検索などがその良い例である．
ある画像と似た画像を探したい．単純に考えると，他の画像とのピクセルレベルでの距離を計算し，近いものから取得してくるという方法が挙げられる．しかしこれには2つの問題がついてくる．それは

\begin{itemize}
	\item ピクセルレベルの距離が近いものが欲しい画像とは限らない
	\item 検索に時間がかかる
\end{itemize}

例えば左上に赤いリンゴが移った図のような写真を入力にして，他のリンゴ画像を得ようとする．しかし，図とのピクセルレベルでの距離は同じリンゴが写っているにも関わらずピクセルレベルの値の距離は大きい．これはリンゴが写っている位置が異なるために生じてしまう．また，この画像が仮に幅640px，高さ480pxだとすると$640 \times 480 = 307,200$の距離計算を行なう必要がある．

そこで，深層特徴を用いることで画像をより小さいサイズでより高次元の情報を保持した特徴に変換することで検索性能を高めることができる．先程述べた通り深層特徴は中間層の出力であり，よく用いられるネットワーク(VGG，AlexNet．ResNetなど)ではおよそ1,024-4,096次元程度のコンパクトなベクトルを得ることが出来る．
また深層特徴は(ネットワークを訓練したタスクによるが)単純なRGBではない高度な情報を保持する．この画像にどのようなものが写っているか，のような情報である．これにより色が似ているといった単純な情報以外を利用した検索が可能になる．


\subsubsection{深層特徴の抽出方法}
単純にネットワークを組んでデータを入れて中間層の値を得たとしてもそれは有用な情報ではない．
ネットワークのパラメータがデタラメなため何の意味もない値が出てくるだけである．
有用な深層特徴を得ようと思ったら，CNNを訓練しておく必要がある．

訓練の仕方は様々である．一般的には「深層特徴を利用するケースとなるべく近い形でDNNを訓練する」というのが基本である．
例えば先程の「リンゴ画像を検索したい」という例では「リンゴが写っているか否か」のDNNを訓練しその中間層を利用するという手がある．しかし普通はもう少し幅の広い課題を解くことが多く，またDNNの訓練に必要な大規模データも手に入ることは少ない．
そこでImageNetというデータセットを利用して，ImageNetデータセットの分類問題を学習したDNNの中間層出力を深層特徴として利用することが多い．
ImageNetは大量の画像を「人」「車」「鳥」のようなそこに写っているもので分類したデータセットのことであり，このデータセットで訓練したDNNモデルは他の領域にも応用しやすい汎用的な特徴表現能力を得ることが知られている．

そのため，「取り敢えず深層特徴を使いたい！」という場合は有名なネットワークをImageNetで訓練してその中間層出力を利用するケースがほとんどである．


次の章で実際に深層特徴を用いて画像検索を行なう例を見てみる．


\subsubsection{深層特徴抽出の実装}
長々書いてきたが要は深層特徴とは「データから抽出したいい感じの特徴」であり，非常に有用なものである．そのためChainerでは深層特徴を非常に簡単に得る事ができるように設計されている．


{\bf 実装課題}\\
search.pyとcreate\_db.pyを使用します
   \begin{practice}
    search.pyのargparse部分をよく読んでcifar10/test/以下から適当に画像を選んでsearch.pyをCPU上で実行せよ。
   \end{practice}
   \begin{practice}
   search.pyの中で深層特徴(src\_df)を計算する部分を探し，深層特徴のshapeを表示せよ．
   \end{practice}
   \begin{practice}
    create\_db.pyの中で深層特徴として使用する隠れ層を指定している部分を探し，VGG16のfc6層を利用するよう書き換えよ．その後もう一度search.pyを実行せよ．
   \end{practice}
   \begin{practice}
    MNISTでMLPを訓練し，その隠れ層出力を深層特徴として利用した場合の検索結果を表示せよ
    かなり難易度は高いのでTAを利用してください．
   \end{practice}


\subsection{GAN}
詳細は触れないがCNNは分類/回帰以外にも利用可能である．一例として画像生成技術であるGenerative Adversarial Network，通称GANを挙げる．
GANはgeneratorとdiscriminatorという2つのCNNを用いる．generatorは何らかの適当な入力から1枚の画像を生成するCNNである．
discriminatorは入力された画像がgeneratorが作ったものか実際の画像かを判定するCNNである．
訓練の最初の方ではgeneratorはわけの分からない画像を出力する．しかしdiscriminatorもあまり賢くないのでgeneratorの画像と実際の画像を見分けることが出来ない．その後，訓練が進むとdiscriminatorも賢くなり，generatorから出てきた画像を見抜けるようになる．そこで，generatorの損失関数をうまく設定することで，generatorはdiscriminatorを騙せるような画像を生成させるように訓練する．

generatorはdiscriminatorを騙せるような画像を生成しようとし，discriminatorはgeneratorから出てきた画像を見抜こうとする．お互いがお互いを刺激しあって学習することでgeneratorはより本物っぽい画像を生成することが出来る様になる．

Deep Convolutional GAN (通称DCGAN) の実装はchainer/examples/dcganの中にある．
generatorとdiscriminatorの定義を見つけてみよう．
また，このコードではupdaterを自作している．updaterはバッチを受け取ってモデルに通し，損失を計算してモデルの更新を行なうよう支持する場所である．
updaterはStandardUpdaterを継承してupdate\_core関数を上書きして作るのだが，もし特殊な学習を行いたければここを参考にすると良い．

\subsection{Super Resolution}
画像生成とは微妙に異なるが，CNNを利用して低画質の画像を高画質に変換しようとするものもある．
低画質の画像にはない情報を推測するのでもちろん正確な高画質画像を作ることは不可能だが，GANと組み合わせて利用するといかにも高画質画像に見える画像を生成することが出来る．